{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7bc6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 497.6 MB 21 kB/s s eta 0:00:01     |████████▋                       | 134.3 MB 9.6 MB/s eta 0:00:39\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: setuptools in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=05d41f2c1eb294650b1ce7e3c274f34b0b1d44c13eeda83fccc2a36a7130155f\n",
      "  Stored in directory: /home/vividlee/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc40503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/vividlee/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.62\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5219c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 13:54:08.653972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-08 13:54:08.654027: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vividlee/Desktop/YeloCar\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "# Data : ALL\n",
    "\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c356c0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 16:46:59.418362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-18 16:46:59.418479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-18 16:46:59.418545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-18 16:46:59.445869: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-18 16:46:59.446023: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-18 16:46:59.447289: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-18 16:46:59.447818: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 16:46:59.506480: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6347022336 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "673/673 [==============================] - 114s 168ms/step - loss: 0.0079 - mae: 0.0588 - mse: 0.0079 - val_loss: 0.0111 - val_mae: 0.0724 - val_mse: 0.0111\n",
      "Epoch 2/100\n",
      "673/673 [==============================] - 112s 167ms/step - loss: 0.0061 - mae: 0.0506 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0754 - val_mse: 0.0122\n",
      "Epoch 3/100\n",
      "673/673 [==============================] - 113s 167ms/step - loss: 0.0057 - mae: 0.0489 - mse: 0.0057 - val_loss: 0.0133 - val_mae: 0.0792 - val_mse: 0.0133\n",
      "Epoch 4/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0053 - mae: 0.0475 - mse: 0.0053 - val_loss: 0.0127 - val_mae: 0.0777 - val_mse: 0.0127\n",
      "\n",
      "\n",
      "1351/1351 [==============================] - 8s 6ms/step - loss: 0.0127 - mae: 0.0777 - mse: 0.0127\n",
      "[0.012657422572374344, 0.07773271203041077, 0.012657422572374344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 16:54:42.334409: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test1/model_deep4pc_test1/assets\n"
     ]
    }
   ],
   "source": [
    "dataset_version = 'deep4pc_test1'\n",
    "model_version = 'model_' + dataset_version\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "# model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "# print(model.evaluate(x_test, y_test))\n",
    "# model.summary()\n",
    "\n",
    "# model = tf.saved_model.load('./Model/Model_' + dataset_version + '/' + model_version)\n",
    "# outputs = model(x_test[0:10])\n",
    "\n",
    "# print(outputs)\n",
    "\n",
    "# print(x_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590eb2e",
   "metadata": {},
   "source": [
    "## dataset : 'deep4pc_test1'\n",
    "### Epoch 12/100 673/673 [==============================] - 113s 168ms/step - loss: 0.0038 - mae: 0.0413 - mse: 0.0038 - val_loss: 0.0123 - val_mae: 0.0777 - val_mse: 0.0123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af908b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21179/3569524578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_version\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Model/Model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_version\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/dataset_hsv_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_version\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maction_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_version = 'deep4pc_test1'\n",
    "model_version = 'model_' + dataset_version + '_2'\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "# model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "# print(model.evaluate(x_test, y_test))\n",
    "# model.summary()\n",
    "\n",
    "# model = tf.saved_model.load('./Model/Model_' + dataset_version + '/' + model_version)\n",
    "# outputs = model(x_test[0:10])\n",
    "\n",
    "# print(outputs)\n",
    "\n",
    "# print(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b41594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bae3e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.4722335  0.1559705 ]\n",
      " [0.47223353 0.15597047]\n",
      " [0.47223586 0.15597549]\n",
      " [0.47223628 0.15597016]\n",
      " [0.4722375  0.15596777]\n",
      " [0.4722398  0.15596272]\n",
      " [0.4722401  0.15596005]\n",
      " [0.47224066 0.15596175]\n",
      " [0.472234   0.15597227]\n",
      " [0.4722414  0.15596355]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "x_tested = x_test[0:10]\n",
    "# print(type(x_test[0:10]))\n",
    "# print(x_test[0:10].shape)\n",
    "# print(type(x_tested))\n",
    "# print(x_tested.shape)\n",
    "\n",
    "outputs = model(x_tested)\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "x_tested *= 255\n",
    "\n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('filename_' + str(i) + '.jpeg', x_tested[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "654cfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "130c5665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 23, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 18:40:03.627758: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6347022336 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "673/673 [==============================] - 121s 179ms/step - loss: 0.0079 - mae: 0.0583 - mse: 0.0079 - val_loss: 0.0122 - val_mae: 0.0776 - val_mse: 0.0122\n",
      "Epoch 2/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0061 - mae: 0.0506 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0766 - val_mse: 0.0118\n",
      "Epoch 3/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0056 - mae: 0.0488 - mse: 0.0056 - val_loss: 0.0132 - val_mae: 0.0802 - val_mse: 0.0132\n",
      "Epoch 4/100\n",
      "673/673 [==============================] - 114s 170ms/step - loss: 0.0052 - mae: 0.0475 - mse: 0.0052 - val_loss: 0.0129 - val_mae: 0.0785 - val_mse: 0.0129\n",
      "Epoch 5/100\n",
      "673/673 [==============================] - 113s 169ms/step - loss: 0.0049 - mae: 0.0462 - mse: 0.0049 - val_loss: 0.0126 - val_mae: 0.0771 - val_mse: 0.0126\n",
      "Epoch 6/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0047 - mae: 0.0452 - mse: 0.0047 - val_loss: 0.0119 - val_mae: 0.0750 - val_mse: 0.0119\n",
      "Epoch 7/100\n",
      "673/673 [==============================] - 120s 179ms/step - loss: 0.0045 - mae: 0.0444 - mse: 0.0045 - val_loss: 0.0123 - val_mae: 0.0768 - val_mse: 0.0123\n",
      "Epoch 8/100\n",
      "673/673 [==============================] - 120s 178ms/step - loss: 0.0043 - mae: 0.0435 - mse: 0.0043 - val_loss: 0.0120 - val_mae: 0.0761 - val_mse: 0.0120\n",
      "Epoch 9/100\n",
      "673/673 [==============================] - 120s 178ms/step - loss: 0.0042 - mae: 0.0429 - mse: 0.0042 - val_loss: 0.0115 - val_mae: 0.0753 - val_mse: 0.0115\n",
      "Epoch 10/100\n",
      "673/673 [==============================] - 121s 180ms/step - loss: 0.0040 - mae: 0.0423 - mse: 0.0040 - val_loss: 0.0120 - val_mae: 0.0756 - val_mse: 0.0120\n",
      "Epoch 11/100\n",
      "673/673 [==============================] - 118s 176ms/step - loss: 0.0039 - mae: 0.0416 - mse: 0.0039 - val_loss: 0.0121 - val_mae: 0.0765 - val_mse: 0.0121\n",
      "Epoch 12/100\n",
      "673/673 [==============================] - 118s 175ms/step - loss: 0.0038 - mae: 0.0411 - mse: 0.0038 - val_loss: 0.0124 - val_mae: 0.0766 - val_mse: 0.0124\n",
      "Epoch 13/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0037 - mae: 0.0406 - mse: 0.0037 - val_loss: 0.0127 - val_mae: 0.0774 - val_mse: 0.0127\n",
      "Epoch 14/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0036 - mae: 0.0401 - mse: 0.0036 - val_loss: 0.0124 - val_mae: 0.0772 - val_mse: 0.0124\n",
      "Epoch 15/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0035 - mae: 0.0396 - mse: 0.0035 - val_loss: 0.0126 - val_mae: 0.0770 - val_mse: 0.0126\n",
      "Epoch 16/100\n",
      "673/673 [==============================] - 114s 170ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0119 - val_mae: 0.0758 - val_mse: 0.0119\n",
      "Epoch 17/100\n",
      "673/673 [==============================] - 114s 170ms/step - loss: 0.0033 - mae: 0.0388 - mse: 0.0033 - val_loss: 0.0124 - val_mae: 0.0767 - val_mse: 0.0124\n",
      "Epoch 18/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0033 - mae: 0.0384 - mse: 0.0033 - val_loss: 0.0129 - val_mae: 0.0778 - val_mse: 0.0129\n",
      "Epoch 19/100\n",
      "673/673 [==============================] - 113s 169ms/step - loss: 0.0032 - mae: 0.0381 - mse: 0.0032 - val_loss: 0.0120 - val_mae: 0.0761 - val_mse: 0.0120\n",
      "\n",
      "\n",
      "1351/1351 [==============================] - 8s 6ms/step - loss: 0.0120 - mae: 0.0761 - mse: 0.0120\n",
      "[0.01203683391213417, 0.07614171504974365, 0.01203683391213417]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test1/model_deep4pc_test1_3_patience15/assets\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ./script/Model/model_deep4pc_test1_3_patience15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13584/2868789532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./script/Model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             raise ImportError(\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at ./script/Model/model_deep4pc_test1_3_patience15"
     ]
    }
   ],
   "source": [
    "dataset_version = 'deep4pc_test1'\n",
    "\n",
    "model_version = 'model_' + dataset_version + '_3_patience10'\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "# x_test *= 255\n",
    "\n",
    "createFolder('./Test/' + model_version)    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f04f250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 23, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 19:34:06.316865: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6347022336 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0080 - mae: 0.0591 - mse: 0.0080 - val_loss: 0.0113 - val_mae: 0.0724 - val_mse: 0.0113\n",
      "Epoch 2/100\n",
      "673/673 [==============================] - 115s 170ms/step - loss: 0.0061 - mae: 0.0508 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0744 - val_mse: 0.0121\n",
      "Epoch 3/100\n",
      "673/673 [==============================] - 116s 172ms/step - loss: 0.0056 - mae: 0.0491 - mse: 0.0056 - val_loss: 0.0126 - val_mae: 0.0770 - val_mse: 0.0126\n",
      "Epoch 4/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0053 - mae: 0.0478 - mse: 0.0053 - val_loss: 0.0136 - val_mae: 0.0819 - val_mse: 0.0136\n",
      "Epoch 5/100\n",
      "673/673 [==============================] - 115s 170ms/step - loss: 0.0050 - mae: 0.0466 - mse: 0.0050 - val_loss: 0.0136 - val_mae: 0.0812 - val_mse: 0.0136\n",
      "Epoch 6/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0048 - mae: 0.0456 - mse: 0.0048 - val_loss: 0.0123 - val_mae: 0.0760 - val_mse: 0.0123\n",
      "Epoch 7/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0046 - mae: 0.0447 - mse: 0.0046 - val_loss: 0.0132 - val_mae: 0.0800 - val_mse: 0.0132\n",
      "Epoch 8/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0044 - mae: 0.0439 - mse: 0.0044 - val_loss: 0.0125 - val_mae: 0.0772 - val_mse: 0.0125\n",
      "Epoch 9/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0042 - mae: 0.0432 - mse: 0.0042 - val_loss: 0.0125 - val_mae: 0.0772 - val_mse: 0.0125\n",
      "Epoch 10/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0041 - mae: 0.0425 - mse: 0.0041 - val_loss: 0.0119 - val_mae: 0.0756 - val_mse: 0.0119\n",
      "Epoch 11/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0040 - mae: 0.0419 - mse: 0.0040 - val_loss: 0.0132 - val_mae: 0.0794 - val_mse: 0.0132\n",
      "Epoch 12/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0038 - mae: 0.0413 - mse: 0.0038 - val_loss: 0.0125 - val_mae: 0.0787 - val_mse: 0.0125\n",
      "Epoch 13/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0037 - mae: 0.0408 - mse: 0.0037 - val_loss: 0.0121 - val_mae: 0.0773 - val_mse: 0.0121\n",
      "Epoch 14/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0036 - mae: 0.0403 - mse: 0.0036 - val_loss: 0.0132 - val_mae: 0.0795 - val_mse: 0.0132\n",
      "Epoch 15/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0035 - mae: 0.0398 - mse: 0.0035 - val_loss: 0.0123 - val_mae: 0.0766 - val_mse: 0.0123\n",
      "Epoch 16/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0034 - mae: 0.0393 - mse: 0.0034 - val_loss: 0.0120 - val_mae: 0.0759 - val_mse: 0.0120\n",
      "\n",
      "\n",
      "1351/1351 [==============================] - 8s 6ms/step - loss: 0.0120 - mae: 0.0759 - mse: 0.0120\n",
      "[0.011963579803705215, 0.0759456604719162, 0.011963579803705215]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test1/model_deep4pc_test1_4_patience15/assets\n",
      "tf.Tensor(\n",
      "[[0.43886167 0.22632778]\n",
      " [0.43877345 0.22626138]\n",
      " [0.42824417 0.22447696]\n",
      " [0.43654782 0.22672191]\n",
      " [0.44261718 0.22586262]\n",
      " [0.44665474 0.23005962]\n",
      " [0.4439299  0.2185157 ]\n",
      " [0.42507362 0.22574061]\n",
      " [0.44006503 0.22927663]\n",
      " [0.4232236  0.22405426]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dataset_version = 'deep4pc_test1'\n",
    "model_version = 'model_' + dataset_version + '_4_patience15'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb362c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 23, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "673/673 [==============================] - 117s 173ms/step - loss: 0.0082 - mae: 0.0598 - mse: 0.0082 - val_loss: 0.0111 - val_mae: 0.0709 - val_mse: 0.0111\n",
      "Epoch 2/100\n",
      "673/673 [==============================] - 116s 172ms/step - loss: 0.0062 - mae: 0.0514 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0762 - val_mse: 0.0121\n",
      "Epoch 3/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0057 - mae: 0.0494 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0732 - val_mse: 0.0113\n",
      "Epoch 4/100\n",
      "673/673 [==============================] - 112s 167ms/step - loss: 0.0053 - mae: 0.0480 - mse: 0.0053 - val_loss: 0.0126 - val_mae: 0.0763 - val_mse: 0.0126\n",
      "Epoch 5/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0051 - mae: 0.0468 - mse: 0.0051 - val_loss: 0.0122 - val_mae: 0.0772 - val_mse: 0.0122\n",
      "Epoch 6/100\n",
      "673/673 [==============================] - 112s 167ms/step - loss: 0.0048 - mae: 0.0458 - mse: 0.0048 - val_loss: 0.0118 - val_mae: 0.0758 - val_mse: 0.0118\n",
      "Epoch 7/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0046 - mae: 0.0449 - mse: 0.0046 - val_loss: 0.0126 - val_mae: 0.0769 - val_mse: 0.0126\n",
      "Epoch 8/100\n",
      "673/673 [==============================] - 112s 166ms/step - loss: 0.0044 - mae: 0.0441 - mse: 0.0044 - val_loss: 0.0123 - val_mae: 0.0759 - val_mse: 0.0123\n",
      "Epoch 9/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0043 - mae: 0.0434 - mse: 0.0043 - val_loss: 0.0117 - val_mae: 0.0754 - val_mse: 0.0117\n",
      "Epoch 10/100\n",
      "673/673 [==============================] - 112s 167ms/step - loss: 0.0041 - mae: 0.0427 - mse: 0.0041 - val_loss: 0.0114 - val_mae: 0.0755 - val_mse: 0.0114\n",
      "Epoch 11/100\n",
      "673/673 [==============================] - 113s 167ms/step - loss: 0.0040 - mae: 0.0420 - mse: 0.0040 - val_loss: 0.0121 - val_mae: 0.0765 - val_mse: 0.0121\n",
      "Epoch 12/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0039 - mae: 0.0415 - mse: 0.0039 - val_loss: 0.0125 - val_mae: 0.0779 - val_mse: 0.0125\n",
      "Epoch 13/100\n",
      "673/673 [==============================] - 114s 169ms/step - loss: 0.0038 - mae: 0.0409 - mse: 0.0038 - val_loss: 0.0120 - val_mae: 0.0758 - val_mse: 0.0120\n",
      "Epoch 14/100\n",
      "673/673 [==============================] - 115s 170ms/step - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0120 - val_mae: 0.0763 - val_mse: 0.0120\n",
      "Epoch 15/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0036 - mae: 0.0399 - mse: 0.0036 - val_loss: 0.0133 - val_mae: 0.0796 - val_mse: 0.0133\n",
      "Epoch 16/100\n",
      "673/673 [==============================] - 114s 170ms/step - loss: 0.0035 - mae: 0.0394 - mse: 0.0035 - val_loss: 0.0125 - val_mae: 0.0769 - val_mse: 0.0125\n",
      "Epoch 17/100\n",
      "673/673 [==============================] - 113s 167ms/step - loss: 0.0034 - mae: 0.0390 - mse: 0.0034 - val_loss: 0.0118 - val_mae: 0.0759 - val_mse: 0.0118\n",
      "Epoch 18/100\n",
      "673/673 [==============================] - 113s 169ms/step - loss: 0.0033 - mae: 0.0386 - mse: 0.0033 - val_loss: 0.0119 - val_mae: 0.0759 - val_mse: 0.0119\n",
      "Epoch 19/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0032 - mae: 0.0382 - mse: 0.0032 - val_loss: 0.0124 - val_mae: 0.0770 - val_mse: 0.0124\n",
      "Epoch 20/100\n",
      "673/673 [==============================] - 112s 167ms/step - loss: 0.0031 - mae: 0.0378 - mse: 0.0031 - val_loss: 0.0122 - val_mae: 0.0764 - val_mse: 0.0122\n",
      "Epoch 21/100\n",
      "673/673 [==============================] - 113s 168ms/step - loss: 0.0031 - mae: 0.0375 - mse: 0.0031 - val_loss: 0.0123 - val_mae: 0.0770 - val_mse: 0.0123\n",
      "\n",
      "\n",
      "1351/1351 [==============================] - 8s 6ms/step - loss: 0.0123 - mae: 0.0770 - mse: 0.0123\n",
      "[0.01234130747616291, 0.07698855549097061, 0.01234130747616291]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test1/model_deep4pc_test1_5_patience20/assets\n",
      "tf.Tensor(\n",
      "[[0.44611198 0.2246198 ]\n",
      " [0.44631714 0.22457689]\n",
      " [0.44251376 0.22330725]\n",
      " [0.4389289  0.2146389 ]\n",
      " [0.44431502 0.2241931 ]\n",
      " [0.45500773 0.22362521]\n",
      " [0.46371597 0.23295009]\n",
      " [0.4592693  0.23467666]\n",
      " [0.42749733 0.2166513 ]\n",
      " [0.44787854 0.2265297 ]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dataset_version = 'deep4pc_test1'\n",
    "model_version = 'model_' + dataset_version + '_5_patience20'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd340d25",
   "metadata": {},
   "source": [
    "## dataset : 'deep4pc_test1' + 'deep4pc_test2_existing'\n",
    "### Epoch 28/100 38/38 [==============================] - 6s 165ms/step - loss: 0.0029 - mae: 0.0324 - mse: 0.0029 - val_loss: 0.0038 - val_mae: 0.0358 - val_mse: 0.0038\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf40920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 16:34:46.674535: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-07 16:34:46.674635: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-07 16:34:46.674701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-07 16:34:46.700481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-07 16:34:46.700584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-07 16:34:46.701630: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-07 16:34:46.702317: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 7s 168ms/step - loss: 0.0247 - mae: 0.1017 - mse: 0.0247 - val_loss: 0.0133 - val_mae: 0.0898 - val_mse: 0.0133\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0110 - mae: 0.0746 - mse: 0.0110 - val_loss: 0.0067 - val_mae: 0.0597 - val_mse: 0.0067\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0092 - mae: 0.0672 - mse: 0.0092 - val_loss: 0.0163 - val_mae: 0.1058 - val_mse: 0.0163\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 6s 161ms/step - loss: 0.0081 - mae: 0.0615 - mse: 0.0081 - val_loss: 0.0060 - val_mae: 0.0547 - val_mse: 0.0060\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 6s 161ms/step - loss: 0.0074 - mae: 0.0573 - mse: 0.0074 - val_loss: 0.0070 - val_mae: 0.0624 - val_mse: 0.0070\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 160ms/step - loss: 0.0069 - mae: 0.0546 - mse: 0.0069 - val_loss: 0.0060 - val_mae: 0.0500 - val_mse: 0.0060\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0066 - mae: 0.0522 - mse: 0.0066 - val_loss: 0.0053 - val_mae: 0.0477 - val_mse: 0.0053\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0062 - mae: 0.0494 - mse: 0.0062 - val_loss: 0.0034 - val_mae: 0.0349 - val_mse: 0.0034\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 166ms/step - loss: 0.0059 - mae: 0.0471 - mse: 0.0059 - val_loss: 0.0036 - val_mae: 0.0384 - val_mse: 0.0036\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 167ms/step - loss: 0.0056 - mae: 0.0460 - mse: 0.0056 - val_loss: 0.0034 - val_mae: 0.0333 - val_mse: 0.0034\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0055 - mae: 0.0457 - mse: 0.0055 - val_loss: 0.0034 - val_mae: 0.0353 - val_mse: 0.0034\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0054 - mae: 0.0445 - mse: 0.0054 - val_loss: 0.0034 - val_mae: 0.0346 - val_mse: 0.0034\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 6s 168ms/step - loss: 0.0051 - mae: 0.0432 - mse: 0.0051 - val_loss: 0.0039 - val_mae: 0.0362 - val_mse: 0.0039\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.0050 - mae: 0.0425 - mse: 0.0050 - val_loss: 0.0037 - val_mae: 0.0355 - val_mse: 0.0037\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 6s 166ms/step - loss: 0.0047 - mae: 0.0411 - mse: 0.0047 - val_loss: 0.0047 - val_mae: 0.0435 - val_mse: 0.0047\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 7s 172ms/step - loss: 0.0046 - mae: 0.0407 - mse: 0.0046 - val_loss: 0.0040 - val_mae: 0.0340 - val_mse: 0.0040\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 6s 171ms/step - loss: 0.0044 - mae: 0.0396 - mse: 0.0044 - val_loss: 0.0036 - val_mae: 0.0329 - val_mse: 0.0036\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.0043 - mae: 0.0390 - mse: 0.0043 - val_loss: 0.0036 - val_mae: 0.0356 - val_mse: 0.0036\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.0041 - mae: 0.0384 - mse: 0.0041 - val_loss: 0.0037 - val_mae: 0.0355 - val_mse: 0.0037\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0039 - mae: 0.0375 - mse: 0.0039 - val_loss: 0.0036 - val_mae: 0.0348 - val_mse: 0.0036\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 6s 166ms/step - loss: 0.0038 - mae: 0.0369 - mse: 0.0038 - val_loss: 0.0037 - val_mae: 0.0357 - val_mse: 0.0037\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.0036 - mae: 0.0358 - mse: 0.0036 - val_loss: 0.0039 - val_mae: 0.0345 - val_mse: 0.0039\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0035 - mae: 0.0354 - mse: 0.0035 - val_loss: 0.0047 - val_mae: 0.0375 - val_mse: 0.0047\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 6s 167ms/step - loss: 0.0034 - mae: 0.0349 - mse: 0.0034 - val_loss: 0.0046 - val_mae: 0.0381 - val_mse: 0.0046\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.0033 - mae: 0.0345 - mse: 0.0033 - val_loss: 0.0038 - val_mae: 0.0340 - val_mse: 0.0038\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 6s 171ms/step - loss: 0.0031 - mae: 0.0335 - mse: 0.0031 - val_loss: 0.0055 - val_mae: 0.0440 - val_mse: 0.0055\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 0.0031 - mae: 0.0331 - mse: 0.0031 - val_loss: 0.0043 - val_mae: 0.0364 - val_mse: 0.0043\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0029 - mae: 0.0324 - mse: 0.0029 - val_loss: 0.0038 - val_mae: 0.0358 - val_mse: 0.0038\n",
      "\n",
      "\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0358 - mse: 0.0038\n",
      "[0.0038162567652761936, 0.03582308441400528, 0.0038162567652761936]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 16:37:45.210683: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test2_existing/model_deep4pc_test2_existing_5_patience20/assets\n",
      "tf.Tensor(\n",
      "[[0.90058583 0.22449778]\n",
      " [0.9784754  0.22367086]\n",
      " [1.0318474  0.20568928]\n",
      " [0.8807407  0.21662639]\n",
      " [0.94416195 0.19423714]\n",
      " [0.8018071  0.20891562]\n",
      " [0.77657753 0.19982907]\n",
      " [0.7426489  0.20155053]\n",
      " [0.6980996  0.19960107]\n",
      " [0.90882    0.19041562]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test1'\n",
    "dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version_existing + '_5_patience20'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "with h5py.File('./Model/Model_' + dataset_version_existing + '/dataset_hsv_' + dataset_version_existing + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6733d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 7s 168ms/step - loss: 0.0224 - mae: 0.1002 - mse: 0.0224 - val_loss: 0.0051 - val_mae: 0.0462 - val_mse: 0.0051\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 6s 170ms/step - loss: 0.0108 - mae: 0.0759 - mse: 0.0108 - val_loss: 0.0049 - val_mae: 0.0439 - val_mse: 0.0049\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0087 - mae: 0.0648 - mse: 0.0087 - val_loss: 0.0059 - val_mae: 0.0594 - val_mse: 0.0059\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0087 - mae: 0.0638 - mse: 0.0087 - val_loss: 0.0037 - val_mae: 0.0425 - val_mse: 0.0037\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0072 - mae: 0.0560 - mse: 0.0072 - val_loss: 0.0046 - val_mae: 0.0391 - val_mse: 0.0046\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0070 - mae: 0.0541 - mse: 0.0070 - val_loss: 0.0033 - val_mae: 0.0368 - val_mse: 0.0033\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0064 - mae: 0.0512 - mse: 0.0064 - val_loss: 0.0045 - val_mae: 0.0450 - val_mse: 0.0045\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0061 - mae: 0.0490 - mse: 0.0061 - val_loss: 0.0032 - val_mae: 0.0328 - val_mse: 0.0032\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0057 - mae: 0.0470 - mse: 0.0057 - val_loss: 0.0045 - val_mae: 0.0480 - val_mse: 0.0045\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0057 - mae: 0.0473 - mse: 0.0057 - val_loss: 0.0035 - val_mae: 0.0343 - val_mse: 0.0035\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0054 - mae: 0.0451 - mse: 0.0054 - val_loss: 0.0049 - val_mae: 0.0428 - val_mse: 0.0049\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0051 - mae: 0.0430 - mse: 0.0051 - val_loss: 0.0053 - val_mae: 0.0463 - val_mse: 0.0053\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0050 - mae: 0.0434 - mse: 0.0050 - val_loss: 0.0036 - val_mae: 0.0348 - val_mse: 0.0036\n",
      "\n",
      "\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0348 - mse: 0.0036\n",
      "[0.003615471301600337, 0.034762993454933167, 0.003615471301600337]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test2_existing/model_deep4pc_test2_existing_6_patience5/assets\n",
      "tf.Tensor(\n",
      "[[0.83483493 0.20815018]\n",
      " [0.79196155 0.20783246]\n",
      " [0.8098312  0.20739585]\n",
      " [0.74360496 0.19450858]\n",
      " [0.7800198  0.21202347]\n",
      " [0.7326631  0.20302472]\n",
      " [0.7435966  0.21823484]\n",
      " [0.74349725 0.22257724]\n",
      " [0.7072864  0.2226837 ]\n",
      " [0.687645   0.2054976 ]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test1'\n",
    "dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version_existing + '_6_patience5'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "with h5py.File('./Model/Model_' + dataset_version_existing + '/dataset_hsv_' + dataset_version_existing + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73976f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 23, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 7s 168ms/step - loss: 0.0227 - mae: 0.1016 - mse: 0.0227 - val_loss: 0.0057 - val_mae: 0.0472 - val_mse: 0.0057\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0111 - mae: 0.0759 - mse: 0.0111 - val_loss: 0.0044 - val_mae: 0.0433 - val_mse: 0.0044\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0089 - mae: 0.0662 - mse: 0.0089 - val_loss: 0.0040 - val_mae: 0.0407 - val_mse: 0.0040\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0080 - mae: 0.0607 - mse: 0.0080 - val_loss: 0.0039 - val_mae: 0.0380 - val_mse: 0.0039\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0074 - mae: 0.0577 - mse: 0.0074 - val_loss: 0.0035 - val_mae: 0.0367 - val_mse: 0.0035\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0068 - mae: 0.0533 - mse: 0.0068 - val_loss: 0.0042 - val_mae: 0.0377 - val_mse: 0.0042\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0062 - mae: 0.0491 - mse: 0.0062 - val_loss: 0.0040 - val_mae: 0.0407 - val_mse: 0.0040\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0062 - mae: 0.0494 - mse: 0.0062 - val_loss: 0.0033 - val_mae: 0.0336 - val_mse: 0.0033\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0056 - mae: 0.0459 - mse: 0.0056 - val_loss: 0.0034 - val_mae: 0.0359 - val_mse: 0.0034\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0056 - mae: 0.0455 - mse: 0.0056 - val_loss: 0.0035 - val_mae: 0.0328 - val_mse: 0.0035\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0054 - mae: 0.0445 - mse: 0.0054 - val_loss: 0.0054 - val_mae: 0.0461 - val_mse: 0.0054\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0052 - mae: 0.0435 - mse: 0.0052 - val_loss: 0.0077 - val_mae: 0.0629 - val_mse: 0.0077\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0049 - mae: 0.0415 - mse: 0.0049 - val_loss: 0.0039 - val_mae: 0.0371 - val_mse: 0.0039\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0049 - mae: 0.0423 - mse: 0.0049 - val_loss: 0.0033 - val_mae: 0.0337 - val_mse: 0.0033\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0046 - mae: 0.0402 - mse: 0.0046 - val_loss: 0.0042 - val_mae: 0.0343 - val_mse: 0.0042\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0044 - mae: 0.0393 - mse: 0.0044 - val_loss: 0.0035 - val_mae: 0.0330 - val_mse: 0.0035\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0043 - mae: 0.0388 - mse: 0.0043 - val_loss: 0.0047 - val_mae: 0.0371 - val_mse: 0.0047\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0041 - mae: 0.0378 - mse: 0.0041 - val_loss: 0.0038 - val_mae: 0.0335 - val_mse: 0.0038\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0039 - mae: 0.0368 - mse: 0.0039 - val_loss: 0.0051 - val_mae: 0.0415 - val_mse: 0.0051\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 6s 162ms/step - loss: 0.0039 - mae: 0.0371 - mse: 0.0039 - val_loss: 0.0039 - val_mae: 0.0378 - val_mse: 0.0039\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0037 - mae: 0.0362 - mse: 0.0037 - val_loss: 0.0047 - val_mae: 0.0417 - val_mse: 0.0047\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0036 - mae: 0.0355 - mse: 0.0036 - val_loss: 0.0041 - val_mae: 0.0368 - val_mse: 0.0041\n",
      "\n",
      "\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0368 - mse: 0.0041\n",
      "[0.004082745406776667, 0.03681434318423271, 0.004082745406776667]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test2_existing/model_deep4pc_test2_existing_7_patience8/assets\n",
      "tf.Tensor(\n",
      "[[0.9746191  0.19167347]\n",
      " [0.9276811  0.18936297]\n",
      " [0.92203355 0.2067812 ]\n",
      " [0.7988617  0.19383448]\n",
      " [0.6993307  0.20239477]\n",
      " [0.7674164  0.20392793]\n",
      " [0.8024354  0.21478432]\n",
      " [0.7371019  0.20508194]\n",
      " [0.73293674 0.2033011 ]\n",
      " [0.72808826 0.2112277 ]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test1'\n",
    "dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version_existing + '_7_patience8'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "with h5py.File('./Model/Model_' + dataset_version_existing + '/dataset_hsv_' + dataset_version_existing + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c12279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 23, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 7s 168ms/step - loss: 0.0214 - mae: 0.1009 - mse: 0.0214 - val_loss: 0.0081 - val_mae: 0.0724 - val_mse: 0.0081\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0098 - mae: 0.0694 - mse: 0.0098 - val_loss: 0.0047 - val_mae: 0.0512 - val_mse: 0.0047\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0088 - mae: 0.0654 - mse: 0.0088 - val_loss: 0.0045 - val_mae: 0.0456 - val_mse: 0.0045\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0081 - mae: 0.0605 - mse: 0.0081 - val_loss: 0.0034 - val_mae: 0.0382 - val_mse: 0.0034\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0075 - mae: 0.0580 - mse: 0.0075 - val_loss: 0.0041 - val_mae: 0.0365 - val_mse: 0.0041\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0070 - mae: 0.0546 - mse: 0.0070 - val_loss: 0.0041 - val_mae: 0.0452 - val_mse: 0.0041\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0067 - mae: 0.0524 - mse: 0.0067 - val_loss: 0.0035 - val_mae: 0.0396 - val_mse: 0.0035\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0065 - mae: 0.0518 - mse: 0.0065 - val_loss: 0.0053 - val_mae: 0.0438 - val_mse: 0.0053\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0064 - mae: 0.0511 - mse: 0.0064 - val_loss: 0.0076 - val_mae: 0.0573 - val_mse: 0.0076\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0061 - mae: 0.0488 - mse: 0.0061 - val_loss: 0.0078 - val_mae: 0.0635 - val_mse: 0.0078\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0058 - mae: 0.0474 - mse: 0.0058 - val_loss: 0.0033 - val_mae: 0.0356 - val_mse: 0.0033\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0059 - mae: 0.0482 - mse: 0.0059 - val_loss: 0.0034 - val_mae: 0.0337 - val_mse: 0.0034\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0054 - mae: 0.0453 - mse: 0.0054 - val_loss: 0.0047 - val_mae: 0.0434 - val_mse: 0.0047\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0054 - mae: 0.0459 - mse: 0.0054 - val_loss: 0.0041 - val_mae: 0.0357 - val_mse: 0.0041\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0052 - mae: 0.0449 - mse: 0.0052 - val_loss: 0.0054 - val_mae: 0.0487 - val_mse: 0.0054\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0050 - mae: 0.0435 - mse: 0.0050 - val_loss: 0.0033 - val_mae: 0.0336 - val_mse: 0.0033\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0049 - mae: 0.0423 - mse: 0.0049 - val_loss: 0.0048 - val_mae: 0.0414 - val_mse: 0.0048\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0047 - mae: 0.0418 - mse: 0.0047 - val_loss: 0.0070 - val_mae: 0.0553 - val_mse: 0.0070\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0045 - mae: 0.0410 - mse: 0.0045 - val_loss: 0.0033 - val_mae: 0.0341 - val_mse: 0.0033\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0044 - mae: 0.0402 - mse: 0.0044 - val_loss: 0.0038 - val_mae: 0.0380 - val_mse: 0.0038\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0043 - mae: 0.0403 - mse: 0.0043 - val_loss: 0.0037 - val_mae: 0.0374 - val_mse: 0.0037\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0040 - mae: 0.0387 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0347 - val_mse: 0.0035\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0039 - mae: 0.0377 - mse: 0.0039 - val_loss: 0.0044 - val_mae: 0.0359 - val_mse: 0.0044\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0037 - mae: 0.0370 - mse: 0.0037 - val_loss: 0.0040 - val_mae: 0.0350 - val_mse: 0.0040\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0036 - mae: 0.0369 - mse: 0.0036 - val_loss: 0.0072 - val_mae: 0.0541 - val_mse: 0.0072\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0035 - mae: 0.0355 - mse: 0.0035 - val_loss: 0.0057 - val_mae: 0.0477 - val_mse: 0.0057\n",
      "\n",
      "\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0477 - mse: 0.0057\n",
      "[0.005680795293301344, 0.047696687281131744, 0.005680795293301344]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test2_existing/model_deep4pc_test2_existing_8_patience10/assets\n",
      "tf.Tensor(\n",
      "[[0.79723847 0.19568044]\n",
      " [0.8220673  0.19870126]\n",
      " [0.7703848  0.20057613]\n",
      " [0.7277488  0.21411365]\n",
      " [0.72908735 0.22141996]\n",
      " [0.706526   0.20703945]\n",
      " [0.6598819  0.22686175]\n",
      " [0.6845015  0.23231503]\n",
      " [0.658911   0.23037091]\n",
      " [0.61768633 0.22046152]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test1'\n",
    "dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version_existing + '_8_patience10'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "with h5py.File('./Model/Model_' + dataset_version_existing + '/dataset_hsv_' + dataset_version_existing + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:10])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 10) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cace8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 23, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 7s 168ms/step - loss: 0.0279 - mae: 0.0968 - mse: 0.0279 - val_loss: 0.0253 - val_mae: 0.1360 - val_mse: 0.0253\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0118 - mae: 0.0786 - mse: 0.0118 - val_loss: 0.0121 - val_mae: 0.0880 - val_mse: 0.0121\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0090 - mae: 0.0668 - mse: 0.0090 - val_loss: 0.0082 - val_mae: 0.0705 - val_mse: 0.0082\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0080 - mae: 0.0607 - mse: 0.0080 - val_loss: 0.0047 - val_mae: 0.0471 - val_mse: 0.0047\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0074 - mae: 0.0566 - mse: 0.0074 - val_loss: 0.0039 - val_mae: 0.0432 - val_mse: 0.0039\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0067 - mae: 0.0538 - mse: 0.0067 - val_loss: 0.0035 - val_mae: 0.0351 - val_mse: 0.0035\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0065 - mae: 0.0519 - mse: 0.0065 - val_loss: 0.0039 - val_mae: 0.0385 - val_mse: 0.0039\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0059 - mae: 0.0478 - mse: 0.0059 - val_loss: 0.0038 - val_mae: 0.0406 - val_mse: 0.0038\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0060 - mae: 0.0481 - mse: 0.0060 - val_loss: 0.0072 - val_mae: 0.0568 - val_mse: 0.0072\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0057 - mae: 0.0467 - mse: 0.0057 - val_loss: 0.0036 - val_mae: 0.0334 - val_mse: 0.0036\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 6s 165ms/step - loss: 0.0054 - mae: 0.0451 - mse: 0.0054 - val_loss: 0.0033 - val_mae: 0.0348 - val_mse: 0.0033\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0052 - mae: 0.0444 - mse: 0.0052 - val_loss: 0.0036 - val_mae: 0.0320 - val_mse: 0.0036\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0049 - mae: 0.0423 - mse: 0.0049 - val_loss: 0.0035 - val_mae: 0.0352 - val_mse: 0.0035\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0047 - mae: 0.0413 - mse: 0.0047 - val_loss: 0.0050 - val_mae: 0.0419 - val_mse: 0.0050\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0046 - mae: 0.0409 - mse: 0.0046 - val_loss: 0.0054 - val_mae: 0.0422 - val_mse: 0.0054\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0043 - mae: 0.0397 - mse: 0.0043 - val_loss: 0.0045 - val_mae: 0.0400 - val_mse: 0.0045\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0042 - mae: 0.0395 - mse: 0.0042 - val_loss: 0.0038 - val_mae: 0.0338 - val_mse: 0.0038\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0040 - mae: 0.0379 - mse: 0.0040 - val_loss: 0.0036 - val_mae: 0.0331 - val_mse: 0.0036\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0039 - mae: 0.0377 - mse: 0.0039 - val_loss: 0.0045 - val_mae: 0.0369 - val_mse: 0.0045\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0037 - mae: 0.0368 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0380 - val_mse: 0.0037\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0036 - mae: 0.0364 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0326 - val_mse: 0.0036\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0035 - mae: 0.0360 - mse: 0.0035 - val_loss: 0.0041 - val_mae: 0.0369 - val_mse: 0.0041\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0033 - mae: 0.0351 - mse: 0.0033 - val_loss: 0.0051 - val_mae: 0.0431 - val_mse: 0.0051\n",
      "\n",
      "\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0431 - mse: 0.0051\n",
      "[0.005137323401868343, 0.04305187985301018, 0.005137323401868343]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test2_existing/model_deep4pc_test2_existing_9_patience12/assets\n",
      "tf.Tensor(\n",
      "[[0.79576963 0.21068063]\n",
      " [0.7811986  0.20821589]\n",
      " [0.8537521  0.20818523]\n",
      " [0.69718224 0.20384918]\n",
      " [0.6571477  0.20398057]\n",
      " [0.8264949  0.17922029]\n",
      " [0.68093914 0.20106988]\n",
      " [0.7062551  0.19328448]\n",
      " [0.6833685  0.20405546]\n",
      " [0.5845119  0.20458396]\n",
      " [0.68956953 0.21614304]\n",
      " [0.805508   0.20316587]\n",
      " [0.720541   0.25050306]\n",
      " [0.5582461  0.23415866]\n",
      " [0.49088967 0.23658885]\n",
      " [0.62701803 0.20411408]\n",
      " [0.6209304  0.19923635]\n",
      " [0.6331014  0.2001237 ]\n",
      " [0.61533314 0.19580065]\n",
      " [0.61862314 0.20544307]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test1'\n",
    "dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version_existing + '_9_patience12'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "with h5py.File('./Model/Model_' + dataset_version_existing + '/dataset_hsv_' + dataset_version_existing + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7c2f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 23, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 7s 167ms/step - loss: 0.0246 - mae: 0.0956 - mse: 0.0246 - val_loss: 0.0133 - val_mae: 0.0869 - val_mse: 0.0133\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0102 - mae: 0.0723 - mse: 0.0102 - val_loss: 0.0116 - val_mae: 0.0899 - val_mse: 0.0116\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0091 - mae: 0.0671 - mse: 0.0091 - val_loss: 0.0100 - val_mae: 0.0768 - val_mse: 0.0100\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0081 - mae: 0.0615 - mse: 0.0081 - val_loss: 0.0073 - val_mae: 0.0584 - val_mse: 0.0073\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0074 - mae: 0.0567 - mse: 0.0074 - val_loss: 0.0078 - val_mae: 0.0641 - val_mse: 0.0078\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0067 - mae: 0.0531 - mse: 0.0067 - val_loss: 0.0049 - val_mae: 0.0478 - val_mse: 0.0049\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0066 - mae: 0.0517 - mse: 0.0066 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0062 - mae: 0.0500 - mse: 0.0062 - val_loss: 0.0118 - val_mae: 0.0835 - val_mse: 0.0118\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0061 - mae: 0.0491 - mse: 0.0061 - val_loss: 0.0037 - val_mae: 0.0339 - val_mse: 0.0037\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0057 - mae: 0.0459 - mse: 0.0057 - val_loss: 0.0062 - val_mae: 0.0535 - val_mse: 0.0062\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0056 - mae: 0.0462 - mse: 0.0056 - val_loss: 0.0035 - val_mae: 0.0346 - val_mse: 0.0035\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0053 - mae: 0.0451 - mse: 0.0053 - val_loss: 0.0065 - val_mae: 0.0548 - val_mse: 0.0065\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0053 - mae: 0.0450 - mse: 0.0053 - val_loss: 0.0054 - val_mae: 0.0447 - val_mse: 0.0054\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0050 - mae: 0.0435 - mse: 0.0050 - val_loss: 0.0046 - val_mae: 0.0399 - val_mse: 0.0046\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0048 - mae: 0.0421 - mse: 0.0048 - val_loss: 0.0037 - val_mae: 0.0388 - val_mse: 0.0037\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0045 - mae: 0.0405 - mse: 0.0045 - val_loss: 0.0092 - val_mae: 0.0700 - val_mse: 0.0092\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0046 - mae: 0.0415 - mse: 0.0046 - val_loss: 0.0058 - val_mae: 0.0502 - val_mse: 0.0058\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0043 - mae: 0.0394 - mse: 0.0043 - val_loss: 0.0048 - val_mae: 0.0412 - val_mse: 0.0048\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0042 - mae: 0.0392 - mse: 0.0042 - val_loss: 0.0064 - val_mae: 0.0517 - val_mse: 0.0064\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0040 - mae: 0.0385 - mse: 0.0040 - val_loss: 0.0044 - val_mae: 0.0412 - val_mse: 0.0044\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0040 - mae: 0.0391 - mse: 0.0040 - val_loss: 0.0038 - val_mae: 0.0351 - val_mse: 0.0038\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0037 - mae: 0.0371 - mse: 0.0037 - val_loss: 0.0037 - val_mae: 0.0336 - val_mse: 0.0037\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0037 - mae: 0.0372 - mse: 0.0037 - val_loss: 0.0036 - val_mae: 0.0331 - val_mse: 0.0036\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 6s 163ms/step - loss: 0.0035 - mae: 0.0359 - mse: 0.0035 - val_loss: 0.0044 - val_mae: 0.0362 - val_mse: 0.0044\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0034 - mae: 0.0351 - mse: 0.0034 - val_loss: 0.0056 - val_mae: 0.0485 - val_mse: 0.0056\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 6s 164ms/step - loss: 0.0033 - mae: 0.0348 - mse: 0.0033 - val_loss: 0.0037 - val_mae: 0.0355 - val_mse: 0.0037\n",
      "\n",
      "\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0355 - mse: 0.0037\n",
      "[0.0036657669115811586, 0.03545185551047325, 0.0036657669115811586]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test2_existing/model_deep4pc_test2_existing_10_patience15/assets\n",
      "tf.Tensor(\n",
      "[[0.88646275 0.18445301]\n",
      " [0.97168165 0.18780583]\n",
      " [0.9131005  0.20594579]\n",
      " [0.9090837  0.21203199]\n",
      " [0.7328255  0.20599568]\n",
      " [0.7710759  0.21946403]\n",
      " [0.8082831  0.22800636]\n",
      " [0.69138026 0.2367846 ]\n",
      " [0.74379194 0.23373103]\n",
      " [0.92869616 0.2363553 ]\n",
      " [0.8836616  0.23235148]\n",
      " [0.7652673  0.23332202]\n",
      " [0.74651706 0.2282939 ]\n",
      " [0.5860021  0.25810024]\n",
      " [0.5542134  0.25359216]\n",
      " [0.6495167  0.23911092]\n",
      " [0.606364   0.23205   ]\n",
      " [0.6312034  0.24508941]\n",
      " [0.66479945 0.2425046 ]\n",
      " [0.6555296  0.25354975]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test1'\n",
    "dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version_existing + '_10_patience15'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "with h5py.File('./Model/Model_' + dataset_version_existing + '/dataset_hsv_' + dataset_version_existing + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version_existing + '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "571ccbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 23, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 18:46:08.306570: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6699405312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0081 - mae: 0.0584 - mse: 0.0081 - val_loss: 0.0111 - val_mae: 0.0716 - val_mse: 0.0111\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 116s 164ms/step - loss: 0.0061 - mae: 0.0504 - mse: 0.0061 - val_loss: 0.0115 - val_mae: 0.0720 - val_mse: 0.0115\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 117s 164ms/step - loss: 0.0056 - mae: 0.0487 - mse: 0.0056 - val_loss: 0.0118 - val_mae: 0.0743 - val_mse: 0.0118\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0053 - mae: 0.0474 - mse: 0.0053 - val_loss: 0.0114 - val_mae: 0.0729 - val_mse: 0.0114\n",
      "\n",
      "\n",
      "1426/1426 [==============================] - 8s 6ms/step - loss: 0.0114 - mae: 0.0729 - mse: 0.0114\n",
      "[0.011382139287889004, 0.07289628684520721, 0.011382139287889004]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test3_all/model_deep4pc_test3_all_1_patience3/assets\n",
      "tf.Tensor(\n",
      "[[0.45389885 0.22172397]\n",
      " [0.4535658  0.22185788]\n",
      " [0.4499451  0.22151601]\n",
      " [0.47217613 0.19564009]\n",
      " [0.47662222 0.1879775 ]\n",
      " [0.44408756 0.22746429]\n",
      " [0.44332957 0.21937397]\n",
      " [0.44513857 0.2205154 ]\n",
      " [0.43611723 0.20913213]\n",
      " [0.44122553 0.19930518]\n",
      " [0.43586123 0.2261951 ]\n",
      " [0.40967238 0.22369292]\n",
      " [0.4096959  0.2236399 ]\n",
      " [0.41374072 0.22736064]\n",
      " [0.43145978 0.2287299 ]\n",
      " [0.4322871  0.22869655]\n",
      " [0.4291458  0.2096489 ]\n",
      " [0.4294284  0.20963582]\n",
      " [0.42670384 0.23053128]\n",
      " [0.4267646  0.23046365]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one final HDF5\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test3_all'\n",
    "#dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version + '_1_patience3'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version+ '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3245eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 23, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 10, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 4, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 19:00:33.412895: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6699405312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0084 - mae: 0.0594 - mse: 0.0084 - val_loss: 0.0119 - val_mae: 0.0742 - val_mse: 0.0119\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0062 - mae: 0.0508 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0742 - val_mse: 0.0121\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 117s 164ms/step - loss: 0.0057 - mae: 0.0489 - mse: 0.0057 - val_loss: 0.0132 - val_mae: 0.0782 - val_mse: 0.0132\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 117s 164ms/step - loss: 0.0053 - mae: 0.0475 - mse: 0.0053 - val_loss: 0.0119 - val_mae: 0.0742 - val_mse: 0.0119\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0050 - mae: 0.0463 - mse: 0.0050 - val_loss: 0.0116 - val_mae: 0.0726 - val_mse: 0.0116\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0048 - mae: 0.0453 - mse: 0.0048 - val_loss: 0.0126 - val_mae: 0.0771 - val_mse: 0.0126\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0046 - mae: 0.0445 - mse: 0.0046 - val_loss: 0.0127 - val_mae: 0.0780 - val_mse: 0.0127\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0044 - mae: 0.0437 - mse: 0.0044 - val_loss: 0.0116 - val_mae: 0.0739 - val_mse: 0.0116\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0043 - mae: 0.0430 - mse: 0.0043 - val_loss: 0.0117 - val_mae: 0.0741 - val_mse: 0.0117\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0042 - mae: 0.0425 - mse: 0.0042 - val_loss: 0.0121 - val_mae: 0.0748 - val_mse: 0.0121\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 119s 168ms/step - loss: 0.0040 - mae: 0.0419 - mse: 0.0040 - val_loss: 0.0118 - val_mae: 0.0754 - val_mse: 0.0118\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0039 - mae: 0.0413 - mse: 0.0039 - val_loss: 0.0119 - val_mae: 0.0749 - val_mse: 0.0119\n",
      "Epoch 13/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0038 - mae: 0.0408 - mse: 0.0038 - val_loss: 0.0121 - val_mae: 0.0747 - val_mse: 0.0121\n",
      "Epoch 14/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0126 - val_mae: 0.0774 - val_mse: 0.0126\n",
      "\n",
      "\n",
      "1426/1426 [==============================] - 8s 6ms/step - loss: 0.0126 - mae: 0.0774 - mse: 0.0126\n",
      "[0.012609589844942093, 0.07744695991277695, 0.012609589844942093]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test3_all/model_deep4pc_test3_all_2_patience6/assets\n",
      "tf.Tensor(\n",
      "[[0.37620175 0.22815377]\n",
      " [0.37495017 0.22803777]\n",
      " [0.3910005  0.2301271 ]\n",
      " [0.42688924 0.22478506]\n",
      " [0.41923022 0.21934377]\n",
      " [0.3279863  0.21407035]\n",
      " [0.38907844 0.21323858]\n",
      " [0.43925792 0.23353444]\n",
      " [0.4219296  0.23681808]\n",
      " [0.48060375 0.23942773]\n",
      " [0.40270942 0.23480746]\n",
      " [0.38359368 0.22837916]\n",
      " [0.38371944 0.2283269 ]\n",
      " [0.392309   0.24337043]\n",
      " [0.3934865  0.24454609]\n",
      " [0.39547485 0.24475005]\n",
      " [0.44708663 0.236611  ]\n",
      " [0.44730037 0.2366148 ]\n",
      " [0.42884088 0.24116555]\n",
      " [0.4289623  0.24117151]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one final HDF5\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test3_all'\n",
    "#dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version + '_2_patience6'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "# f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version+ '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1a3ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 13:54:48.963393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-02-08 13:54:48.963505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-02-08 13:54:48.963582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-02-08 13:54:48.989414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-02-08 13:54:48.989570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vividlee/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-02-08 13:54:48.990660: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-08 13:54:48.991266: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 13:54:49.075151: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6699405312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "710/710 [==============================] - 120s 167ms/step - loss: 0.0081 - mae: 0.0586 - mse: 0.0081 - val_loss: 0.0117 - val_mae: 0.0739 - val_mse: 0.0117\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 119s 168ms/step - loss: 0.0061 - mae: 0.0507 - mse: 0.0061 - val_loss: 0.0128 - val_mae: 0.0810 - val_mse: 0.0128\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 119s 168ms/step - loss: 0.0057 - mae: 0.0490 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0730 - val_mse: 0.0114\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 117s 164ms/step - loss: 0.0053 - mae: 0.0477 - mse: 0.0053 - val_loss: 0.0119 - val_mae: 0.0763 - val_mse: 0.0119\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0051 - mae: 0.0465 - mse: 0.0051 - val_loss: 0.0118 - val_mae: 0.0749 - val_mse: 0.0118\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0048 - mae: 0.0456 - mse: 0.0048 - val_loss: 0.0119 - val_mae: 0.0751 - val_mse: 0.0119\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 120s 169ms/step - loss: 0.0046 - mae: 0.0448 - mse: 0.0046 - val_loss: 0.0119 - val_mae: 0.0740 - val_mse: 0.0119\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0045 - mae: 0.0441 - mse: 0.0045 - val_loss: 0.0119 - val_mae: 0.0774 - val_mse: 0.0119\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0043 - mae: 0.0434 - mse: 0.0043 - val_loss: 0.0118 - val_mae: 0.0753 - val_mse: 0.0118\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0042 - mae: 0.0428 - mse: 0.0042 - val_loss: 0.0130 - val_mae: 0.0778 - val_mse: 0.0130\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0041 - mae: 0.0422 - mse: 0.0041 - val_loss: 0.0125 - val_mae: 0.0766 - val_mse: 0.0125\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 116s 164ms/step - loss: 0.0040 - mae: 0.0417 - mse: 0.0040 - val_loss: 0.0127 - val_mae: 0.0773 - val_mse: 0.0127\n",
      "\n",
      "\n",
      "1426/1426 [==============================] - 8s 6ms/step - loss: 0.0127 - mae: 0.0773 - mse: 0.0127\n",
      "[0.012723821215331554, 0.0773080587387085, 0.012723821215331554]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 14:18:37.646012: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test3_all/model_deep4pc_test3_all_3_patience9/assets\n",
      "tf.Tensor(\n",
      "[[0.40231705 0.22680396]\n",
      " [0.40230942 0.22686745]\n",
      " [0.40195498 0.22650763]\n",
      " [0.41782853 0.23110434]\n",
      " [0.4265459  0.22921488]\n",
      " [0.44574454 0.2241148 ]\n",
      " [0.4419746  0.22081223]\n",
      " [0.41891798 0.22934283]\n",
      " [0.41181752 0.22817841]\n",
      " [0.42935726 0.22290933]\n",
      " [0.45981333 0.21819475]\n",
      " [0.4414697  0.22807834]\n",
      " [0.44159728 0.2280785 ]\n",
      " [0.44966063 0.2302664 ]\n",
      " [0.39477286 0.22627959]\n",
      " [0.4053612  0.22730774]\n",
      " [0.42451656 0.23390462]\n",
      " [0.42450696 0.23403156]\n",
      " [0.37123662 0.2318321 ]\n",
      " [0.37097827 0.23160622]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one final HDF5\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test3_all'\n",
    "#dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version + '_3_patience9'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "# f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=9)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version+ '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2fd9bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 14:25:30.609703: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6699405312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "710/710 [==============================] - 120s 168ms/step - loss: 0.0081 - mae: 0.0591 - mse: 0.0081 - val_loss: 0.0114 - val_mae: 0.0759 - val_mse: 0.0114\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0062 - mae: 0.0509 - mse: 0.0062 - val_loss: 0.0118 - val_mae: 0.0741 - val_mse: 0.0118\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0057 - mae: 0.0491 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0721 - val_mse: 0.0111\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 120s 169ms/step - loss: 0.0053 - mae: 0.0477 - mse: 0.0053 - val_loss: 0.0112 - val_mae: 0.0728 - val_mse: 0.0112\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0051 - mae: 0.0466 - mse: 0.0051 - val_loss: 0.0115 - val_mae: 0.0732 - val_mse: 0.0115\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0048 - mae: 0.0456 - mse: 0.0048 - val_loss: 0.0118 - val_mae: 0.0736 - val_mse: 0.0118\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0046 - mae: 0.0447 - mse: 0.0046 - val_loss: 0.0128 - val_mae: 0.0778 - val_mse: 0.0128\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 0.0045 - mae: 0.0440 - mse: 0.0045 - val_loss: 0.0123 - val_mae: 0.0756 - val_mse: 0.0123\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0043 - mae: 0.0433 - mse: 0.0043 - val_loss: 0.0114 - val_mae: 0.0739 - val_mse: 0.0114\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0042 - mae: 0.0427 - mse: 0.0042 - val_loss: 0.0120 - val_mae: 0.0742 - val_mse: 0.0120\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0040 - mae: 0.0420 - mse: 0.0040 - val_loss: 0.0125 - val_mae: 0.0762 - val_mse: 0.0125\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0039 - mae: 0.0415 - mse: 0.0039 - val_loss: 0.0124 - val_mae: 0.0774 - val_mse: 0.0124\n",
      "Epoch 13/100\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 0.0038 - mae: 0.0410 - mse: 0.0038 - val_loss: 0.0117 - val_mae: 0.0756 - val_mse: 0.0117\n",
      "Epoch 14/100\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 0.0037 - mae: 0.0405 - mse: 0.0037 - val_loss: 0.0122 - val_mae: 0.0753 - val_mse: 0.0122\n",
      "Epoch 15/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0036 - mae: 0.0401 - mse: 0.0036 - val_loss: 0.0116 - val_mae: 0.0755 - val_mse: 0.0116\n",
      "\n",
      "\n",
      "1426/1426 [==============================] - 8s 5ms/step - loss: 0.0116 - mae: 0.0755 - mse: 0.0116\n",
      "[0.011594489216804504, 0.07554733008146286, 0.011594489216804504]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test3_all/model_deep4pc_test3_all_4_patience12/assets\n",
      "tf.Tensor(\n",
      "[[0.40880567 0.20919885]\n",
      " [0.40942022 0.20901194]\n",
      " [0.41127726 0.21207002]\n",
      " [0.43425277 0.22449505]\n",
      " [0.41416523 0.21465948]\n",
      " [0.45755908 0.20876572]\n",
      " [0.46952212 0.21858999]\n",
      " [0.43964347 0.22283679]\n",
      " [0.4576521  0.22524446]\n",
      " [0.444531   0.22261763]\n",
      " [0.35372505 0.22127506]\n",
      " [0.46452588 0.19628796]\n",
      " [0.4641945  0.19639432]\n",
      " [0.48643014 0.21024498]\n",
      " [0.47913483 0.21492696]\n",
      " [0.47799382 0.21488786]\n",
      " [0.44673082 0.2080094 ]\n",
      " [0.44741574 0.20795283]\n",
      " [0.39613393 0.21948749]\n",
      " [0.39634657 0.21961749]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one final HDF5\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test3_all'\n",
    "#dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version + '_4_patience12'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "# f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version+ '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1765fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 46, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 23, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 21, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 12, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,210\n",
      "Trainable params: 126,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 14:56:17.054262: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6699405312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "710/710 [==============================] - 123s 173ms/step - loss: 0.0079 - mae: 0.0585 - mse: 0.0079 - val_loss: 0.0125 - val_mae: 0.0774 - val_mse: 0.0125\n",
      "Epoch 2/100\n",
      "710/710 [==============================] - 121s 170ms/step - loss: 0.0061 - mae: 0.0508 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0737 - val_mse: 0.0118\n",
      "Epoch 3/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0057 - mae: 0.0491 - mse: 0.0057 - val_loss: 0.0119 - val_mae: 0.0744 - val_mse: 0.0119\n",
      "Epoch 4/100\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 0.0053 - mae: 0.0476 - mse: 0.0053 - val_loss: 0.0114 - val_mae: 0.0738 - val_mse: 0.0114\n",
      "Epoch 5/100\n",
      "710/710 [==============================] - 117s 164ms/step - loss: 0.0050 - mae: 0.0465 - mse: 0.0050 - val_loss: 0.0118 - val_mae: 0.0739 - val_mse: 0.0118\n",
      "Epoch 6/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0048 - mae: 0.0455 - mse: 0.0048 - val_loss: 0.0114 - val_mae: 0.0759 - val_mse: 0.0114\n",
      "Epoch 7/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0046 - mae: 0.0446 - mse: 0.0046 - val_loss: 0.0119 - val_mae: 0.0751 - val_mse: 0.0119\n",
      "Epoch 8/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0044 - mae: 0.0438 - mse: 0.0044 - val_loss: 0.0119 - val_mae: 0.0742 - val_mse: 0.0119\n",
      "Epoch 9/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0043 - mae: 0.0430 - mse: 0.0043 - val_loss: 0.0116 - val_mae: 0.0737 - val_mse: 0.0116\n",
      "Epoch 10/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0041 - mae: 0.0424 - mse: 0.0041 - val_loss: 0.0117 - val_mae: 0.0745 - val_mse: 0.0117\n",
      "Epoch 11/100\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 0.0040 - mae: 0.0417 - mse: 0.0040 - val_loss: 0.0123 - val_mae: 0.0771 - val_mse: 0.0123\n",
      "Epoch 12/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0039 - mae: 0.0412 - mse: 0.0039 - val_loss: 0.0119 - val_mae: 0.0745 - val_mse: 0.0119\n",
      "Epoch 13/100\n",
      "710/710 [==============================] - 117s 165ms/step - loss: 0.0037 - mae: 0.0406 - mse: 0.0037 - val_loss: 0.0126 - val_mae: 0.0769 - val_mse: 0.0126\n",
      "Epoch 14/100\n",
      "710/710 [==============================] - 118s 167ms/step - loss: 0.0036 - mae: 0.0401 - mse: 0.0036 - val_loss: 0.0119 - val_mae: 0.0745 - val_mse: 0.0119\n",
      "Epoch 15/100\n",
      "710/710 [==============================] - 119s 168ms/step - loss: 0.0035 - mae: 0.0396 - mse: 0.0035 - val_loss: 0.0118 - val_mae: 0.0742 - val_mse: 0.0118\n",
      "Epoch 16/100\n",
      "710/710 [==============================] - 121s 171ms/step - loss: 0.0035 - mae: 0.0392 - mse: 0.0035 - val_loss: 0.0117 - val_mae: 0.0745 - val_mse: 0.0117\n",
      "Epoch 17/100\n",
      "710/710 [==============================] - 120s 169ms/step - loss: 0.0034 - mae: 0.0388 - mse: 0.0034 - val_loss: 0.0121 - val_mae: 0.0765 - val_mse: 0.0121\n",
      "Epoch 18/100\n",
      "710/710 [==============================] - 119s 167ms/step - loss: 0.0033 - mae: 0.0384 - mse: 0.0033 - val_loss: 0.0125 - val_mae: 0.0770 - val_mse: 0.0125\n",
      "Epoch 19/100\n",
      "710/710 [==============================] - 118s 166ms/step - loss: 0.0032 - mae: 0.0380 - mse: 0.0032 - val_loss: 0.0124 - val_mae: 0.0762 - val_mse: 0.0124\n",
      "\n",
      "\n",
      "1426/1426 [==============================] - 8s 6ms/step - loss: 0.0124 - mae: 0.0762 - mse: 0.0124\n",
      "[0.012425947934389114, 0.07619259506464005, 0.012425947934389114]\n",
      "INFO:tensorflow:Assets written to: ./Model/Model_deep4pc_test3_all/model_deep4pc_test3_all_5_patience15/assets\n",
      "tf.Tensor(\n",
      "[[0.4544853  0.2265904 ]\n",
      " [0.4541412  0.22641072]\n",
      " [0.44633424 0.22422984]\n",
      " [0.43155485 0.22689718]\n",
      " [0.44922084 0.22679335]\n",
      " [0.42096323 0.23139365]\n",
      " [0.4393363  0.23285767]\n",
      " [0.43098235 0.23037528]\n",
      " [0.4728042  0.23955178]\n",
      " [0.46725714 0.24464846]\n",
      " [0.46765393 0.24992314]\n",
      " [0.38296747 0.22347528]\n",
      " [0.38207978 0.22346205]\n",
      " [0.43078148 0.23742026]\n",
      " [0.46240574 0.24494812]\n",
      " [0.46255797 0.24464181]\n",
      " [0.4561745  0.21892172]\n",
      " [0.4558224  0.2200338 ]\n",
      " [0.4266131  0.2180507 ]\n",
      " [0.42435467 0.21785322]], shape=(20, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one final HDF5\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "dataset_version = 'deep4pc_test3_all'\n",
    "#dataset_version_existing = 'deep4pc_test2_existing'\n",
    "model_version = 'model_' + dataset_version + '_5_patience15'\n",
    "\n",
    "createFolder('./Test/' + model_version)\n",
    "# f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "\n",
    "with h5py.File('./Model/Model_' + dataset_version + '/dataset_hsv_' + dataset_version + '.hdf5', 'r') as hf:\n",
    "    image_train = np.array(hf['x_train'][:, :, :, :])\n",
    "    action_train = np.array(hf['y_train'][:, :])\n",
    "    image_val = np.array(hf['x_val'][:, :, :, :])\n",
    "    action_val = np.array(hf['y_val'][:, :])\n",
    "    \n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = (image_train, action_train), (image_val, action_val)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(48, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), callbacks=[callback])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(model.evaluate(x_test, y_test))\n",
    "\n",
    "\n",
    "# model.save('./script/Model/'+model_version)\n",
    "tf.saved_model.save(model, './Model/Model_' + dataset_version + '/' + model_version)\n",
    "\n",
    "del model\n",
    "\n",
    "#model = tf.keras.models.load_model('./script/Model/'+model_version)\n",
    "#print(model.evaluate(x_test, y_test))\n",
    "#model.summary()\n",
    "\n",
    "model = tf.saved_model.load('./Model/Model_' + dataset_version+ '/' + model_version)\n",
    "#model.summary()\n",
    "outputs = model(x_test[0:20])\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "f = open('./Test/' + model_version + '/' + model_version + '_test.txt', 'a')\n",
    "f.write(\"{}\".format(outputs))\n",
    "\n",
    "x_test *= 255\n",
    "    \n",
    "for i in range (0, 20) :\n",
    "    cv2.imwrite('./Test/' + model_version + '/'+ model_version + '_' + str(i) + '.jpeg', x_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7819f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
